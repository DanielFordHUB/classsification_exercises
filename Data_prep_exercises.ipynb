{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44688581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# turn off pink boxes for demo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import our own acquire module\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd6412",
   "metadata": {},
   "source": [
    "Using the Iris Data:\n",
    "\n",
    "1. Use the function defined in acquire.py to load the iris data.\n",
    "\n",
    "2. Drop the species_id and measurement_id columns.\n",
    "\n",
    "3. Rename the species_name column to just species.\n",
    "\n",
    "4. Create dummy variables of the species name and concatenate onto the iris dataframe. (This is for practice, we don't always have to encode the target, but if we used species as a feature, we would need to encode it).\n",
    "\n",
    "5. Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e8d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function defined in acquire.py to load the iris data.\n",
    "df = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ed7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the species_id and measurement_id columns.\n",
    "df = df.drop(columns = 'species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the species_name column to just species.\n",
    "df = df.rename(columns= {'species_name':'species'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ce2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8cbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca53924",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include = 'number').columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61760b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    plt.hist(df[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad215ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df.columns[[df[col].dtype == 'O' for col in df.columns]]\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f297a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in obj_cols:\n",
    "    print('/------------------------------\\\\')\n",
    "    print(df[col].value_counts())\n",
    "    print('\\n')\n",
    "    print(df[col].value_counts(normalize = True, dropna = False))\n",
    "    print('\\------------------------------/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9039799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df['species'], drop_first=False)\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df], axis =1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c78ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a function named prep_iris that accepts \n",
    "the untransformed iris data, and \n",
    "returns the data with the transformations above applied.\n",
    "'''\n",
    "def prep_iris(df):\n",
    "    \n",
    "    #drop column speciess id\n",
    "    df = df.drop(columns = 'species_id')\n",
    "    \n",
    "    #rename species name column\n",
    "    df = df.rename(columns ={'species_name' : 'species'})\n",
    "    \n",
    "    #create dummiess dataframe\n",
    "    dummy_df = pd.get_dummies(df['species'], drop_first=False)\n",
    "    \n",
    "    #concat dummy with DF\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6b3186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>virginica</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  sepal_length  sepal_width  petal_length  petal_width  setosa  \\\n",
       "0       setosa           5.1          3.5           1.4          0.2       1   \n",
       "1       setosa           4.9          3.0           1.4          0.2       1   \n",
       "2       setosa           4.7          3.2           1.3          0.2       1   \n",
       "3       setosa           4.6          3.1           1.5          0.2       1   \n",
       "4       setosa           5.0          3.6           1.4          0.2       1   \n",
       "..         ...           ...          ...           ...          ...     ...   \n",
       "145  virginica           6.7          3.0           5.2          2.3       0   \n",
       "146  virginica           6.3          2.5           5.0          1.9       0   \n",
       "147  virginica           6.5          3.0           5.2          2.0       0   \n",
       "148  virginica           6.2          3.4           5.4          2.3       0   \n",
       "149  virginica           5.9          3.0           5.1          1.8       0   \n",
       "\n",
       "     versicolor  virginica  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "..          ...        ...  \n",
       "145           0          1  \n",
       "146           0          1  \n",
       "147           0          1  \n",
       "148           0          1  \n",
       "149           0          1  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_iris(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca154477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8037ad0",
   "metadata": {},
   "source": [
    "Using the Titanic dataset\n",
    "\n",
    "Use the function defined in acquire.py to load the Titanic data.\n",
    "\n",
    "Drop any unnecessary, unhelpful, or duplicated columns.\n",
    "\n",
    "Encode the categorical columns. Create dummy variables of the categorical columns and concatenate them onto the dataframe.\n",
    "\n",
    "Create a function named prep_titanic that accepts the raw titanic data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6472b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc31aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ea293",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1358c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['age', 'deck', 'embarked', 'class'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2985e0",
   "metadata": {},
   "source": [
    "Encode the categorical columns. Create dummy variables of the categorical columns and concatenate them onto the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df[['sex', 'embark_town']], dummy_na= False, drop_first=[True,True])\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a20383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_dummy], axis =1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f654f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop(columns = ['age', 'deck', 'embarked', 'class'])\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    \n",
    "    df_dummy = pd.get_dummies(df[['sex', 'embark_town']], dummy_na= False, drop_first=[True,True])\n",
    "    df = pd.concat([df, df_dummy], axis= 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71a250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4e5c2a",
   "metadata": {},
   "source": [
    "Using the Telco dataset\n",
    "\n",
    "Use the function defined in acquire.py to load the Telco data.\n",
    "\n",
    "Drop any unnecessary, unhelpful, or duplicated columns. This could mean dropping foreign key columns but keeping the corresponding string values, for example.\n",
    "\n",
    "Encode the categorical columns. Create dummy variables of the categorical columns and concatenate them onto the dataframe.\n",
    "\n",
    "Create a function named prep_telco that accepts the raw telco data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_telco_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns =['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df[['gender', 'partner', 'dependents', 'phone_service', 'multiple_lines','online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'paperless_billing', 'churn', 'internet_service_type', 'payment_type']], dummy_na=False, drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee172d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop(columns =['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], axis = 1)\n",
    "    \n",
    "    df['total_charges'] = df['total_charges'].str.strip()\n",
    "    df = df[df.total_charges != '']\n",
    "    \n",
    "    df['total_charges'] = df.total_charges.astype(float)\n",
    "    \n",
    "    dummy_df = pd.get_dummies(df[['gender', 'partner', 'dependents', 'phone_service', 'multiple_lines','online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'paperless_billing', 'churn', 'internet_service_type', 'payment_type']], dummy_na=False, drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis =1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2baeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_telco(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
