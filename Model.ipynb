{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f139698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "import sklearn.linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d43189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb465f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce obvious noise\n",
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7e8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What about nulls?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop deck because there are far too many nulls\n",
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e2e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill embark_town with the most common observation\n",
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the observations with missing age\n",
    "# My first thought was empty age values might indicate children\n",
    "# Looks like most of these individuals were traveling alone\n",
    "no_age_info = df[df.age.isna()]\n",
    "no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fare.hist(), no_age_info.fare.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how similar this group is to the population\n",
    "for column in df.drop(columns=[\"age\", \"fare\"]).columns:\n",
    "    print(column)\n",
    "    print(\"Population:\")\n",
    "    print(df[column].value_counts(normalize=True))\n",
    "    print(\"No age\")\n",
    "    print(no_age_info[column].value_counts(normalize=True))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the distribution of values, it appears that no age subgroup is very close to the population\n",
    "# If we needed to be more certain, we could perform hypothesis testing\n",
    "# It looks like there's nothing wildly different about the no age group compared to the population\n",
    "# So we'll impute using the median age\n",
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34133ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca221afd",
   "metadata": {},
   "source": [
    "# 1\n",
    "What is your baseline prediction? \n",
    "\n",
    "What is your baseline accuracy? \n",
    "\n",
    "remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "\n",
    "When you make those predictions, what is your accuracy? \n",
    "\n",
    "This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29659b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a662bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plot_tree(tree1, feature_names = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix - actual on left, predicted on top\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508840f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not-survived is our positive case\n",
    "TP = 265\n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0930bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9e898",
   "metadata": {},
   "source": [
    "# RANDOM FOREST EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make model\n",
    "forest1 = RandomForestClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "#fit model on train\n",
    "forest1.fit(X_train, y_train)\n",
    "\n",
    "#use\n",
    "#evaluate\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "#produce classification report\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusing matrix\n",
    "pd.DataFrame(confusion_matrix(y_predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82441782",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9bbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ceda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop\n",
    "for i in range(2, 11):\n",
    "    #make model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    #fit model on train\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    #use\n",
    "    #evaluate\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    #produce classification report\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f'Train with max depth of {i}. \\n') \n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51728278",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    #make model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    #fit model on train\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    #use\n",
    "    #evaluate\n",
    "    in_sample_accuracy = forest.score(X_train,y_train)\n",
    "    \n",
    "    out_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        'max_depth': i,\n",
    "        'train_accuracy': in_sample_accuracy,\n",
    "        'validate_accuracy': out_sample_accuracy\n",
    "    }\n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b47ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.set_index('max_depth').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff19803",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =[]\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    #model\n",
    "    depth = max_depth - i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth = depth, min_samples_leaf= n_samples, random_state=123)\n",
    "    \n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "    \n",
    "    #use\n",
    "    #eval on train first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        'min_samples_per_leaf': n_samples,\n",
    "        'max_depth': depth,\n",
    "        'train_accuracy': in_sample_accuracy,\n",
    "        'validate_accuracy': out_sample_accuracy\n",
    "        \n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df['difference'] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('max_depth')[['train_accuracy', 'validate_accuracy','difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"max_depth\", y=\"difference\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"min_samples_per_leaf\", y=\"difference\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cb5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"difference\", y=\"validate_accuracy\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66057c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d78c5582",
   "metadata": {},
   "source": [
    "# increase min samp per leaf AND max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5608eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55616ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['train_accuracy', 'validate_accuracy','difference']].plot()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e565ab",
   "metadata": {},
   "source": [
    "# fixed depth and increasing min samp per leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "\n",
    "for i in range(2, 50):\n",
    "    # Make the model\n",
    "    depth = 5\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63534c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index('min_samples_per_leaf')[['train_accuracy', 'validate_accuracy', 'difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,50,5))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ddc15",
   "metadata": {},
   "source": [
    "# KNN Exercisses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['pclass', 'age', 'alone', 'fare']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c1350",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e382a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn classifier with n_neighbour = 1\n",
    "\n",
    "knn1 = KNeighborsClassifier(1)\n",
    "knn1.fit(X_train, y_train)\n",
    "# get_classification_metrics(knn)\n",
    "y_pred = knn1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_train, y_pred, output_dict = True)\n",
    "print('n-neighbor = 1')\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c75a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TN, FP, FN, TP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444596ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(TN, FP, FN, TP):\n",
    "    \n",
    "    ALL = TP + TN + FP + FN\n",
    "    \n",
    "    accuracy = (TP + TN)/ALL # How often did the model get it right?\n",
    "    precision = TP/(TP+FP) # What is the quality of a positive prediction made by the model?\n",
    "    recall = TP/(TP+FN) # How many of the true positives were found?   \n",
    "    \n",
    "    true_positive_rate = TP/(TP+FN) # Same as recall, actually\n",
    "    true_negative_rate = TN/(TN+FP) # How many of the true negatives were found?\n",
    "    false_positive_rate = FP/(FP+TN) # How often did we miss the negative and accidentally call it positive?\n",
    "    false_negative_rate = FN/(FN+TP) # How often did we miss the positive and accidentally call it negative?\n",
    "    \n",
    "    f1_score = 2*(precision*recall)/(precision+recall) # Harmonic mean, good for imbalanced data sets\n",
    "    support_pos = TP + FN # Number of actual positives in the sample\n",
    "    support_neg = FP + TN # Number of actual negatives in the sample\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "    print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "    print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "    print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(f\"Support (0): {support_pos}\")\n",
    "    print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b444140",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(10)\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred = knn2.predict(X_train)\n",
    "\n",
    "report = classification_report(y_train, y_pred, output_dict = True)\n",
    "print('n-neighbor = 10')\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f684ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fdd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(20)\n",
    "knn3.fit(X_train, y_train)\n",
    "y_pred = knn3.predict(X_train)\n",
    "\n",
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "print(\"n_neighbour = 20\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix\n",
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[]\n",
    "\n",
    "for k in range(1, 21):\n",
    "    \n",
    "    #DEFINE\n",
    "    knn = KNeighborsClassifier(n_neighbors= k)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        'k': k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        'validate_accuracy': validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3d74b",
   "metadata": {},
   "source": [
    "# Logistic regression exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a819725",
   "metadata": {},
   "source": [
    "# 1\n",
    "Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74126b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0          0   \n",
       "1         1       1  38.0      1      0  71.2833      0          1   \n",
       "2         1       3  26.0      0      0   7.9250      1          1   \n",
       "3         1       1  35.0      1      0  53.1000      0          1   \n",
       "4         0       3  35.0      0      0   8.0500      1          0   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  embark_town_Queenstown  \\\n",
       "0                       0                        1                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        1                       0   \n",
       "3                       0                        1                       0   \n",
       "4                       0                        1                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)\n",
    "\n",
    "df['is_female'] = (df.sex == 'female').astype('int')\n",
    "\n",
    "dummy_df = pd.get_dummies(df[['embark_town']],dummy_na=False, drop_first=True)\n",
    "df = pd.concat([df,dummy_df], axis =1)\n",
    "\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c663e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "is_female                  0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000a3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b6fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8914eedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6741f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff50ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "#create LOG regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "features = ['age','pclass','fare']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276437d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd73be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcced96a",
   "metadata": {},
   "source": [
    "# 2\n",
    "nclude sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b69347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "#create LOG regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "features = ['age','pclass','fare','is_female']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8fc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c58505",
   "metadata": {},
   "source": [
    "# 3\n",
    "Try out other combinations of features and models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0709b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#ALL FEATURES\n",
    "\n",
    "#create LOG regression\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "#features = ['age','pclass','fare']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit2.fit(X_train, y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit2.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d66a9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "#CLASS WEIGHT BALANCED\n",
    "\n",
    "#create LOG regression\n",
    "logit3 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "#Specify features\n",
    "#features = ['age','pclass','fare']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit3.fit(X_train, y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit3.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31d6db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "#only AGE\n",
    "\n",
    "#create LOG regression\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "features = ['age']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit4.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d288b4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "#only sex\n",
    "\n",
    "#create LOG regression\n",
    "logit41 = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "features = ['is_female']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit41.fit(X_train[features], y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit41.predict(X_train[features])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit41.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5192ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.67\n"
     ]
    }
   ],
   "source": [
    "#only PCLASS\n",
    "\n",
    "#create LOG regression\n",
    "logit5 = LogisticRegression(random_state=123)\n",
    "\n",
    "#Specify features\n",
    "features = ['pclass']\n",
    "\n",
    "# FIT model with specified features\n",
    "logit5.fit(X_train[features], y_train)\n",
    "\n",
    "# predict on same subset\n",
    "y_pred = logit5.predict(X_train[features])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit5.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f056267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features, C hyperparameter approaching 0\n",
      "Baseline is 0.62\n",
      "Accuracy of this Logistic Regression on training set: 0.65\n"
     ]
    }
   ],
   "source": [
    "# All Features, C ~ 0\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit6 = LogisticRegression(random_state=123, C=0.00000000000000001)\n",
    "\n",
    "logit6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit6.predict(X_train)\n",
    "accuracy = logit6.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features, C hyperparameter approaching 0\")\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(f'Accuracy of this Logistic Regression on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ece88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1221dae2",
   "metadata": {},
   "source": [
    "# 4\n",
    "Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17d300d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 model using age, pclass, fare, and is_female as the features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using age, pclass, fare, and is_female as the features')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c268244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       132\n",
      "           1       0.75      0.66      0.70        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.76      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "964befde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       132\n",
      "           1       0.71      0.72      0.72        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.77      0.77       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit3 uses all features and class_weight='balanced'\n",
    "y_pred = logit3.predict(X_validate)\n",
    "\n",
    "print(\"Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b22d8432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit41 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       132\n",
      "           1       0.70      0.66      0.68        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.75      0.74      0.74       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit41 uses is_female\n",
    "features = ['is_female']\n",
    "y_pred = logit41.predict(X_validate[features])\n",
    "\n",
    "print(\"Logit41 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12391d",
   "metadata": {},
   "source": [
    "# 5\n",
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d573854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       110\n",
      "           1       0.76      0.72      0.74        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_test)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7e306",
   "metadata": {},
   "source": [
    "# BONUS 1\n",
    "\n",
    "How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e772a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit3.predict_proba(X_train)\n",
    "\n",
    "\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = ['not-survived', 'survived'])\n",
    "y_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7b941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cf6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2533051",
   "metadata": {},
   "source": [
    "# BONUS 2\n",
    "\n",
    "How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9429ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43909fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3340653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ff5d4e",
   "metadata": {},
   "source": [
    "# BONUS 3\n",
    "\n",
    "scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected. \n",
    "\n",
    "\n",
    "C\n",
    "\\=\n",
    ".01\n",
    ",\n",
    ".1\n",
    ",\n",
    "1\n",
    ",\n",
    "10\n",
    ",\n",
    "100\n",
    ",\n",
    "1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f309c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb93510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8eb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd974cff",
   "metadata": {},
   "source": [
    "# telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d000ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_telco_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be64b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop object columns for ddecision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09688c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_charges'] = df['total_charges'].str.strip()\n",
    "df = df[df.total_charges != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98521391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_charges'] = df.total_charges.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary categorical variables to numeric\n",
    "df['gender_encoded'] = df.gender.map({'Female': 1, 'Male': 0})\n",
    "df['partner_encoded'] = df.partner.map({'Yes': 1, 'No': 0})\n",
    "df['dependents_encoded'] = df.dependents.map({'Yes': 1, 'No': 0})\n",
    "df['phone_service_encoded'] = df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "df['paperless_billing_encoded'] = df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "df['churn_encoded'] = df.churn.map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012048ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies for non-binary categorical variables\n",
    "dummy_df = pd.get_dummies(df[['multiple_lines', \\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type', \\\n",
    "                              'payment_type']], dummy_na=False, \\\n",
    "                              drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b020ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop object columns for ddecision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80217938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=df.churn)\n",
    "train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"churn_encoded\"])\n",
    "y_train = train.churn_encoded\n",
    "\n",
    "X_validate = validate.drop(columns=[\"churn_encoded\"])\n",
    "y_validate = validate.churn_encoded\n",
    "\n",
    "X_test = test.drop(columns=[\"churn_encoded\"])\n",
    "y_test = test.churn_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6faeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.churn_encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9477f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d754d",
   "metadata": {},
   "source": [
    "# Question 2: Fit-Transform\n",
    "\n",
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819135a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10773852",
   "metadata": {},
   "source": [
    "Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace09fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b116cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dc01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58295cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71788c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784e708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
